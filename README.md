# ðŸ“ˆ Human Development Index (GDP) â€” Supervised Learning

This project explores the relationship between various socio-economic factors and their influence on a country's **GDP (Gross Domestic Product)** and **Human Development Index (HDI)**. By applying supervised learning models, we aim to build predictive models that quantify the effects of these variables and offer insights into national development trends.

---

## ðŸŽ¯ Project Objective

The objectives of this project are:

- To analyze the relationship between socio-economic indicators and GDP/HDI.
- To build regression models that can predict GDP and HDI using machine learning.
- To evaluate and compare different regression techniques using performance metrics like RMSE.
- To apply cross-validation for robust model validation.

---

## ðŸ“Š Dataset Overview

The dataset includes the following key variables:

- **Total Cases** â€” Total confirmed disease-related cases.
- **Total Deaths** â€” Total deaths due to health-related issues.
- **Population** â€” Countryâ€™s population.
- **GDP Per Capita** â€” Gross Domestic Product per person.
- **Location** â€” Country name.
- **HDI (Human Development Index)** â€” A composite index measuring average achievement in key dimensions of human development.

---

## ðŸ§ª Methodology

The dataset is divided into:

- **70% Training Data**  
- **30% Testing Data**

To enhance the reliability of the results, **K-Fold Cross Validation** is used during training. This helps reduce bias and variance in model evaluation.

### ðŸ§  Machine Learning Models Used:

- **Linear Regression (Vanilla)**
- **Lasso Regression** â€” L1 regularization (helps with feature selection)
- **Ridge Regression** â€” L2 regularization (shrinks coefficients)
- **ElasticNet Regression** â€” Combines L1 and L2

Each model is trained and validated to assess predictive performance.

---

## ðŸ§® Libraries Used

```python
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import KFold, cross_val_predict
from sklearn.linear_model import LinearRegression, Lasso, Ridge, RidgeCV, LassoCV, ElasticNetCV
from sklearn.pipeline import Pipeline

%matplotlib inline

## ðŸ“ˆ Model Performance (RMSE)

The **Root Mean Squared Error (RMSE)** is used to evaluate the model performance. A lower RMSE value indicates better predictive accuracy.

| Model       | RMSE      |
|-------------|-----------|
| Linear      | 1.397796  |
| Lasso       | 1.397007  |
| Ridge       | 1.397331  |
| ElasticNet  | 1.397227  |

---

### ðŸ“Œ Interpretation

- All models exhibit **very close RMSE values**, indicating consistent performance across methods.
- **Lasso Regression** achieved the lowest RMSE, making it slightly more effective in this case.
- The similarity in performance suggests that:
  - The dataset is well-processed and scaled.
  - There is no major multicollinearity or overfitting.
  - All four models are appropriate for this problem space.

---

## âœ… Conclusion

This project demonstrates that multiple regression models â€” **Linear**, **Lasso**, **Ridge**, and **ElasticNet** â€” perform similarly well on this dataset. Regularized models offer additional robustness and potential for feature selection, with **Lasso Regression** showing a slight edge.
